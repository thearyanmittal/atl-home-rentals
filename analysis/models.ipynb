{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataset\n",
    "df = pd.read_pickle('../data/data.pkl')\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function (root mean squared error)\n",
    "def rmse(model):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    return np.sqrt(-cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=kf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of models to evaluate (GridSearchCV was used to find the best parameters for each model type)\n",
    "models = [\n",
    "    Lasso(alpha=2.173),\n",
    "    Ridge(alpha=24.995),\n",
    "    ElasticNet(alpha=.733, l1_ratio=.992),\n",
    "    Pipeline([('scaler', StandardScaler()), ('svr', SVR(kernel='linear'))]),\n",
    "    RandomForestRegressor(n_estimators=400, max_features=.333, max_depth=None),\n",
    "    AdaBoostRegressor(n_estimators=100, learning_rate=.05),\n",
    "    GradientBoostingRegressor(n_estimators=600, max_depth=4, learning_rate=.05, max_features='sqrt', loss='squared_error'),\n",
    "    XGBRegressor(colsample_bytree=.1, learning_rate=.05, max_depth=4, n_estimators=1000, reg_alpha=.5, reg_lambda=.25)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of using GridSearchCV to tune hyperparameters\n",
    "\n",
    "# params = {\n",
    "#     'max_depth': (3, 4, None),\n",
    "#     'n_estimators': (500, 1000, 2000),\n",
    "#     'colsample_bytree': (.1, .333, .5),\n",
    "#     'reg_alpha': (.25, .5, 75),\n",
    "#     'reg_lambda': (.25, .5, .75)\n",
    "# }\n",
    "# reg = GridSearchCV(XGBRegressor(learning_rate=.05), params, n_jobs=-1)\n",
    "# reg.fit(X, y)\n",
    "# reg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso RMS Error: 643.8068058994882 ± 25.97122056759165\n",
      "Ridge RMS Error: 646.4154030121493 ± 24.026717424669933\n",
      "ElasticNet RMS Error: 644.747005235093 ± 24.67139963088082\n",
      "SVR RMS Error: 680.6346919525198 ± 24.2784569418987\n",
      "RandomForestRegressor RMS Error: 593.7104661927427 ± 21.765800320238014\n",
      "AdaBoostRegressor RMS Error: 733.4535651653056 ± 28.7929547409758\n",
      "GradientBoostingRegressor RMS Error: 571.1583545109514 ± 33.86346885086319\n",
      "XGBRegressor RMS Error: 561.8925051275608 ± 29.550546284032723\n"
     ]
    }
   ],
   "source": [
    "# create and evaluate models\n",
    "for model in models:\n",
    "    score = rmse(model)\n",
    "    model_name = str(model).split('(')[0]\n",
    "    print(f\"{'SVR' if model_name[0] == 'P' else model_name} RMS Error: {score.mean()} \\u00B1 {score.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3543.000000\n",
       "mean      2208.412645\n",
       "std        918.063358\n",
       "min        600.000000\n",
       "25%       1695.000000\n",
       "50%       1995.000000\n",
       "75%       2450.000000\n",
       "max      10000.000000\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to compare the regression results with the price range of the datapoints\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Factors and Coefficients: \n",
      "Full_Baths       1256.193711\n",
      "SQFT_Int          917.906860\n",
      "Median Income     699.180921\n",
      "Age               596.454562\n",
      "Half_Baths        559.761821\n",
      "dtype: float64\n",
      "\n",
      "Bottom Factors and Coefficients: \n",
      "Rooms: Other          -95.543028\n",
      "Style: Brick Front    -99.744197\n",
      "Assoc                -117.129119\n",
      "Households           -134.380591\n",
      "Rooms: Game          -269.949401\n",
      "dtype: float64\n",
      "\n",
      "86 Zero-Coefficient Factors (out of 177)\n"
     ]
    }
   ],
   "source": [
    "# analyze coefficients of regression to see which factors are weighted most heavily\n",
    "\n",
    "lasso = Lasso(alpha=2.173).fit(X, y)\n",
    "coef = pd.Series(lasso.coef_, index=X.columns).sort_values(ascending=False)\n",
    "print(f'Top Factors and Coefficients: \\n{coef[:5]}')\n",
    "print(f'\\nBottom Factors and Coefficients: \\n{coef[-5:]}')\n",
    "print(f'\\n{len(coef[coef == 0])} Zero-Coefficient Factors (out of 177)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "The XGBoost Regressor by far performed the best on this dataset. However, even its root mean square error was about 562 USD. While this model can give a reasonable estimate regarding the price range of a certain rental, it by no means should be used as an exact price calculator. The standard deviation in the error across all folds is only about 30 USD, though, indicating that the model generalizes well.\n",
    "\n",
    "As expected, the Lasso model highly weights factors that were identified in the exploratory phase to have the greatest positive correlation with price, such as the number of full baths, the square footage of the home, and the median income of the area. Interestingly, the model assigns a large negative coefficient to the size of the lot, perhaps indicating that home rentals on large estates go for lower prices. The model also zeroes out 86/177 variables, indicating that only about 90 or fewer of the columns were absolutely necessary to accurately predict pricing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('atl-home-rentals-sIrw7Atm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ae51bed731bf37f97494d6502d8927d782a1982e3461efeaf84bb1330b038a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
